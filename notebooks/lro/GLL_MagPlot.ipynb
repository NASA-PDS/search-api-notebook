{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1132ea5-bdd6-46cc-8f12-796e41d22c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded JSON\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'list'> is not convertible to datetime, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m  \u001b[38;5;66;03m#Remove duplicates and maintain order of mag_data\u001b[39;00m\n\u001b[1;32m    124\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m:mag_time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: mag_tot})\n\u001b[0;32m--> 125\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#now sort values\u001b[39;00m\n\u001b[1;32m    127\u001b[0m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1050\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1050\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:455\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[0;32m--> 455\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[0;32m-> 2177\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2186\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:402\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:540\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <class 'list'> is not convertible to datetime, at position 0"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "import csv\n",
    "import spiceypy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from astropy.time import Time\n",
    "import requests\n",
    "\n",
    "def getsta(mag_time):\n",
    "        #\n",
    "        # Local parameters\n",
    "        #\n",
    "        METAKR = 'getgll.tm'\n",
    "        #\n",
    "        # Load the kernels that this program requires.  We\n",
    "        # will need a leapseconds kernel to convert input\n",
    "        # UTC time strings into ET.  We also will need the\n",
    "        # necessary SPK files with coverage for the bodies\n",
    "        # in which we are interested.\n",
    "        #\n",
    "        spiceypy.furnsh( METAKR )\n",
    "\n",
    "        #\n",
    "        #Prompt the user for the input time string.\n",
    "        # \n",
    "        # start_time_str = '1996-6-11 19:32:00'\n",
    "        row = []\n",
    "        for t in mag_time:\n",
    "\n",
    "                # start_time = datetime.datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                # utctim = start_time + datetime.timedelta(minutes=i*1000)\n",
    "\n",
    "                time_string = t.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                #ephemeris time after iterating\n",
    "                et = spiceypy.str2et( time_string )\n",
    "\n",
    "                #\n",
    "                # Compute the apparent state of GLL as seen from\n",
    "                # Jupiter in the J2000 frame.  All of the ephemeris\n",
    "                # readers return states in units of kilometers and\n",
    "                # kilometers per second.\n",
    "                #\n",
    "                [state, ltime] = spiceypy.spkezr( '5', et,      'J2000',\n",
    "                                                'LT+S',   '-77'       )\n",
    "                row.append([state[0], state[1], state[2], state[3], state[4], state[5]]) \n",
    "        return row\n",
    "                \n",
    "     \n",
    " #\n",
    " # Fetch PDS Data for MAG\n",
    " #                \n",
    "def get_data(url):\n",
    "        parent_response = requests.get(url)\n",
    "\n",
    "        if parent_response.status_code == 200:\n",
    "                print('Successfully loaded JSON')\n",
    "                parent_data = parent_response.json()\n",
    "                parent_urlkey = parent_data['properties'][\"ops:Data_File_Info.ops:file_ref\"][0]\n",
    "                tab_urls_res = requests.get(parent_urlkey)\n",
    "                tab_urls_cont = tab_urls_res.text.splitlines()\n",
    "                #Define mag arrays\n",
    "                mag_time = []\n",
    "                mag_tot = []\n",
    "\n",
    "                for i in range(len(tab_urls_cont)):\n",
    "                        if 'irc' in tab_urls_cont[i].split(',')[1]: #check for body null rate measurements\n",
    "                            time_data, iter_data = get_tabs(tab_urls_cont[i].split(',')[1]) # get rid of column in csv\n",
    "                            mag_time.append(time_data)\n",
    "                            mag_tot.append(iter_data)\n",
    "\n",
    "                # for i in range(1): #range(len(data['data'])):\n",
    "                #         data_url = data['properties'][\"ops:Data_File_Info.ops:file_ref\"][0]#data['data'][i]['properties'][\"ops:Data_File_Info.ops:file_ref\"][0]\n",
    "                #         mag_data = requests.get(data_url)\n",
    "                #         mag_content = mag_data.text\n",
    "                #         lines = mag_content.splitlines()\n",
    "\n",
    "                #         for line in lines:\n",
    "                #                 raw_data = line.split()\n",
    "                #                 mag_time.append(raw_data[0])\n",
    "                #                 mag_tot.append(raw_data[4])\n",
    "\n",
    "        return mag_time, mag_tot\n",
    "\n",
    "\n",
    "def get_tabs(url):\n",
    "        #load lid found from parent collection\n",
    "        lid_response = requests.get('https://pds.nasa.gov/api/search/1/products/'+url)\n",
    "        lid_data = lid_response.json()\n",
    "\n",
    "        time_data = []\n",
    "        iter_data = []\n",
    "        for i in range(1): #range(len(lid_data['data'])):\n",
    "                tab_url = lid_data['properties']['ops:Data_File_Info.ops:file_ref'][0]\n",
    "                #load in tab data\n",
    "                tab_response = requests.get(tab_url)\n",
    "                tab_content = tab_response.text\n",
    "                lines = tab_content.splitlines()\n",
    "\n",
    "                for line in lines:\n",
    "                        raw_data = line.split()\n",
    "                        time_data.append(raw_data[0])\n",
    "                        iter_data.append(raw_data[4])\n",
    "        return time_data, iter_data\n",
    "\n",
    "def remove_non_unique_values(data):\n",
    "    counts = {}\n",
    "    for item in data:\n",
    "        counts[item] = counts.get(item, 0) + 1\n",
    "\n",
    "    unique_values = [item for item, count in counts.items() if count == 1]\n",
    "    return unique_values\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "       \n",
    "       url = \"https://pds.nasa.gov/api/search/1/products/urn:nasa:pds:galileo-mag-jup-calibrated:data-highres-magnetosphere::1.0\"\n",
    "       mag_time, mag_tot = get_data(url)\n",
    "\n",
    "        #Remove duplicates and maintain order of mag_data\n",
    "       df = pd.DataFrame({'time':mag_time, 'data': mag_tot})\n",
    "       df['time'] = pd.to_datetime(df['time'])\n",
    "       #now sort values\n",
    "       df.sort_values('time', inplace = True)\n",
    "       df.drop_duplicates(subset='time', keep ='first', inplace = True)\n",
    "\n",
    "       df.reset_index(drop=True, inplace=True)\n",
    "        #Obtain the position data that corresponds to the measurements\n",
    "       mag_ephem_data = getsta(df['time']) #Takes time input\n",
    "       print(len(mag_ephem_data))\n",
    "\n",
    "\n",
    "       #Fill in the gaps for the ephemeris data\n",
    "       ephem_time = []\n",
    "       start_time = df['time'][0]\n",
    "       for i in range(3000):\n",
    "                # start_time = datetime.datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n",
    "                ephem_time.append(start_time + datetime.timedelta(minutes=i*1000))   \n",
    "       #Grab the states\n",
    "       ephem_data = getsta(ephem_time)\n",
    "\n",
    "       #Create csv for ephemeris data\n",
    "       eph_file = 'data/eph_data2.csv'\n",
    "       with open(eph_file, 'w',newline='') as file:\n",
    "                writer1 = csv.writer(file)\n",
    "                writer1.writerow(['Time', 'X', 'Y', 'Z']) \n",
    "                for i in range(len(ephem_data)):\n",
    "                        writer1.writerow([ephem_time[i].replace(tzinfo=None).isoformat(), float(ephem_data[i][0]), \n",
    "                                          float(ephem_data[i][1]), float(ephem_data[i][2])])  \n",
    "                         \n",
    "       csv_file = 'data/tot_data2.csv'  \n",
    "       with open(csv_file, 'w',newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Time','Magnitude (nT)', 'X', 'Y', 'Z'])\n",
    "                for i in range(len(mag_ephem_data)):\n",
    "                        writer.writerow([df['time'][i].replace(tzinfo=None).isoformat(), float(df['data'][i]),\n",
    "                                          float(mag_ephem_data[i][0]), float(mag_ephem_data[i][1]),\n",
    "                                            float(mag_ephem_data[i][2])])   \n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6395f-3a2c-4f6e-be99-191553a464e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
