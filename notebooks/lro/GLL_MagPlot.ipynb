{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aeb7aa4-d95f-4f15-9877-440e2870e55a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpywwt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mjupyter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m connect_to_app\n\u001B[1;32m     16\u001B[0m wwt \u001B[38;5;241m=\u001B[39m WWTJupyterWidget()\n\u001B[0;32m---> 17\u001B[0m wwt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m connect_to_app()\u001B[38;5;241m.\u001B[39mbecomes_ready()\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/site-packages/pywwt/core.py:565\u001B[0m, in \u001B[0;36mBaseWWTWidget.becomes_ready\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    561\u001B[0m             fut\u001B[38;5;241m.\u001B[39mset_exception(asyncio\u001B[38;5;241m.\u001B[39mTimeoutError())\n\u001B[1;32m    563\u001B[0m     loop\u001B[38;5;241m.\u001B[39mcall_later(timeout, maybe_time_it_out)\n\u001B[0;32m--> 565\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_readyFuture\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[0;31mTimeoutError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "import requests\n",
    "import csv\n",
    "import spiceypy\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "from pywwt.jupyter import WWTJupyterWidget\n",
    "from pywwt.jupyter import connect_to_app\n",
    "wwt = WWTJupyterWidget()\n",
    "wwt = await connect_to_app().becomes_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1132ea5-bdd6-46cc-8f12-796e41d22c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded JSON\n"
     ]
    },
    {
     "ename": "SpiceNOSUCHFILE",
     "evalue": "\n================================================================================\n\nToolkit version: CSPICE_N0067\n\nSPICE(NOSUCHFILE) --\n\nThe attempt to load \"getgll.tm\" by the routine FURNSH failed. It could not be located.\n\nfurnsh_c --> FURNSH --> ZZLDKER\n\n================================================================================",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mSpiceNOSUCHFILE\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/t7/tdt4vrqj57x7cdkbnm27lcbw0000gq/T/ipykernel_57514/1107706868.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m    128\u001B[0m        \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop_duplicates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'time'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeep\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;34m'first'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m        \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m         \u001B[0;31m#Obtain the position data that corresponds to the measurements\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m        \u001B[0mmag_ephem_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetsta\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'time'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m#Takes time input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    133\u001B[0m        \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmag_ephem_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/t7/tdt4vrqj57x7cdkbnm27lcbw0000gq/T/ipykernel_57514/1107706868.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(mag_time)\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0;31m# UTC time strings into ET.  We also will need the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;31m# necessary SPK files with coverage for the bodies\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0;31m# in which we are interested.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m         \u001B[0mspiceypy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfurnsh\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mMETAKR\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0;31m#Prompt the user for the input time string.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/site-packages/spiceypy/spiceypy.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m             \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m             \u001B[0mcheck_for_spice_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.11/site-packages/spiceypy/spiceypy.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(f)\u001B[0m\n\u001B[1;32m    118\u001B[0m         \u001B[0mexplain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetmsg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"EXPLAIN\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0mlong\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetmsg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LONG\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1841\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0mtraceback\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mqcktrc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m200\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m         \u001B[0mreset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 122\u001B[0;31m         raise dynamically_instantiate_spiceyerror(\n\u001B[0m\u001B[1;32m    123\u001B[0m             \u001B[0mshort\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshort\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexplain\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexplain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlong\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlong\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraceback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         )\n",
      "\u001B[0;31mSpiceNOSUCHFILE\u001B[0m: \n================================================================================\n\nToolkit version: CSPICE_N0067\n\nSPICE(NOSUCHFILE) --\n\nThe attempt to load \"getgll.tm\" by the routine FURNSH failed. It could not be located.\n\nfurnsh_c --> FURNSH --> ZZLDKER\n\n================================================================================"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "import csv\n",
    "import spiceypy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from astropy.time import Time\n",
    "import requests\n",
    "\n",
    "def getsta(mag_time):\n",
    "        #\n",
    "        # Local parameters\n",
    "        #\n",
    "        METAKR = 'getgll.tm'\n",
    "        #\n",
    "        # Load the kernels that this program requires.  We\n",
    "        # will need a leapseconds kernel to convert input\n",
    "        # UTC time strings into ET.  We also will need the\n",
    "        # necessary SPK files with coverage for the bodies\n",
    "        # in which we are interested.\n",
    "        #\n",
    "        spiceypy.furnsh( METAKR )\n",
    "\n",
    "        #\n",
    "        #Prompt the user for the input time string.\n",
    "        # \n",
    "        # start_time_str = '1996-6-11 19:32:00'\n",
    "        row = []\n",
    "        for t in mag_time:\n",
    "\n",
    "                # start_time = datetime.datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                # utctim = start_time + datetime.timedelta(minutes=i*1000)\n",
    "\n",
    "                time_string = t.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                #ephemeris time after iterating\n",
    "                et = spiceypy.str2et( time_string )\n",
    "\n",
    "                #\n",
    "                # Compute the apparent state of GLL as seen from\n",
    "                # Jupiter in the J2000 frame.  All of the ephemeris\n",
    "                # readers return states in units of kilometers and\n",
    "                # kilometers per second.\n",
    "                #\n",
    "                [state, ltime] = spiceypy.spkezr( '5', et,      'J2000',\n",
    "                                                'LT+S',   '-77'       )\n",
    "                row.append([state[0], state[1], state[2], state[3], state[4], state[5]]) \n",
    "        return row\n",
    "                \n",
    "     \n",
    " #\n",
    " # Fetch PDS Data for MAG\n",
    " #                \n",
    "def get_data(url):\n",
    "        parent_response = requests.get(url)\n",
    "\n",
    "        if parent_response.status_code == 200:\n",
    "                print('Successfully loaded JSON')\n",
    "                parent_data = parent_response.json()\n",
    "                parent_urlkey = parent_data['properties'][\"ops:Data_File_Info.ops:file_ref\"][0]\n",
    "                tab_urls_res = requests.get(parent_urlkey)\n",
    "                tab_urls_cont = tab_urls_res.text.splitlines()\n",
    "                #Define mag arrays\n",
    "                mag_time = []\n",
    "                mag_tot = []\n",
    "\n",
    "                for i in range(len(tab_urls_cont)):\n",
    "                        if 'irc' in tab_urls_cont[i].split(',')[1]: #check for body null rate measurements\n",
    "                            time_data, iter_data = get_tabs(tab_urls_cont[i].split(',')[1]) # get rid of column in csv\n",
    "                            mag_time.extend(time_data)\n",
    "                            mag_tot.extend(iter_data)\n",
    "\n",
    "                # for i in range(1): #range(len(data['data'])):\n",
    "                #         data_url = data['properties'][\"ops:Data_File_Info.ops:file_ref\"][0]#data['data'][i]['properties'][\"ops:Data_File_Info.ops:file_ref\"][0]\n",
    "                #         mag_data = requests.get(data_url)\n",
    "                #         mag_content = mag_data.text\n",
    "                #         lines = mag_content.splitlines()\n",
    "\n",
    "                #         for line in lines:\n",
    "                #                 raw_data = line.split()\n",
    "                #                 mag_time.append(raw_data[0])\n",
    "                #                 mag_tot.append(raw_data[4])\n",
    "\n",
    "        return mag_time, mag_tot\n",
    "\n",
    "\n",
    "def get_tabs(url):\n",
    "        #load lid found from parent collection\n",
    "        lid_response = requests.get('https://pds.nasa.gov/api/search/1/products/'+url)\n",
    "        lid_data = lid_response.json()\n",
    "\n",
    "        time_data = []\n",
    "        iter_data = []\n",
    "        for i in range(1): #range(len(lid_data['data'])):\n",
    "                tab_url = lid_data['properties']['ops:Data_File_Info.ops:file_ref'][0]\n",
    "                #load in tab data\n",
    "                tab_response = requests.get(tab_url)\n",
    "                tab_content = tab_response.text\n",
    "                lines = tab_content.splitlines()\n",
    "\n",
    "                for line in lines:\n",
    "                        raw_data = line.split()\n",
    "                        time_data.append(raw_data[0])\n",
    "                        iter_data.append(float(raw_data[4]))\n",
    "        return time_data, iter_data\n",
    "\n",
    "def remove_non_unique_values(data):\n",
    "    counts = {}\n",
    "    for item in data:\n",
    "        counts[item] = counts.get(item, 0) + 1\n",
    "\n",
    "    unique_values = [item for item, count in counts.items() if count == 1]\n",
    "    return unique_values\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "       \n",
    "       url = \"https://pds.nasa.gov/api/search/1/products/urn:nasa:pds:galileo-mag-jup-calibrated:data-highres-magnetosphere::1.0\"\n",
    "       mag_time, mag_tot = get_data(url)\n",
    "\n",
    "        #Remove duplicates and maintain order of mag_data\n",
    "       df = pd.DataFrame({'time':mag_time, 'data': mag_tot})\n",
    "       df['time'] = pd.to_datetime(df['time'])\n",
    "       #now sort values\n",
    "       df.sort_values('time', inplace = True)\n",
    "       df.drop_duplicates(subset='time', keep ='first', inplace = True)\n",
    "\n",
    "       df.reset_index(drop=True, inplace=True)\n",
    "        #Obtain the position data that corresponds to the measurements\n",
    "       mag_ephem_data = getsta(df['time']) #Takes time input\n",
    "       print(len(mag_ephem_data))\n",
    "\n",
    "\n",
    "       #Fill in the gaps for the ephemeris data\n",
    "       ephem_time = []\n",
    "       start_time = df['time'][0]\n",
    "       for i in range(3000):\n",
    "                # start_time = datetime.datetime.strptime(t, \"%Y-%m-%d %H:%M:%S\")\n",
    "                ephem_time.append(start_time + datetime.timedelta(minutes=i*1000))   \n",
    "       #Grab the states\n",
    "       ephem_data = getsta(ephem_time)\n",
    "\n",
    "       #Create csv for ephemeris data\n",
    "       eph_file = 'data/eph_data2.csv'\n",
    "       with open(eph_file, 'w',newline='') as file:\n",
    "                writer1 = csv.writer(file)\n",
    "                writer1.writerow(['Time', 'X', 'Y', 'Z']) \n",
    "                for i in range(len(ephem_data)):\n",
    "                        writer1.writerow([ephem_time[i].replace(tzinfo=None).isoformat(), float(ephem_data[i][0]), \n",
    "                                          float(ephem_data[i][1]), float(ephem_data[i][2])])  \n",
    "                         \n",
    "       csv_file = 'data/comp_tot_data2.csv'  \n",
    "       with open(csv_file, 'w',newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Time','Magnitude (nT)', 'X', 'Y', 'Z'])\n",
    "                for i in range(0,len(mag_ephem_data),100):\n",
    "                        writer.writerow([df['time'][i].replace(tzinfo=None).isoformat(), float(df['data'][i]),\n",
    "                                          float(mag_ephem_data[i][0]), float(mag_ephem_data[i][1]),\n",
    "                                            float(mag_ephem_data[i][2])])   \n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6395f-3a2c-4f6e-be99-191553a464e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
